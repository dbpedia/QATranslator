{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt_new",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy0VN0TiJrut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9gqnIWYQYRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "  sentence = unicode_to_ascii(sentence.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)\n",
        "\n",
        "  sentence = sentence.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  sentence = '<start> ' + sentence + ' <end>'\n",
        "  return sentence"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngXrvN0DQw3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "# def create_dataset(data):\n",
        "#   # lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "#   data = [preprocess_sentence(sentence) for sentence in data]\n",
        "\n",
        "#   return data "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W__xelYQ0nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('/content/drive/My Drive/data/template/en-es-train-template.csv')\n",
        "df_train=df_train.dropna(subset=['input_lang','output_lang'])\n",
        "\n",
        "\n",
        "# df = pd.read_csv('/content/drive/My Drive/data/template/en-es-test-template.csv')\n",
        "# df=df.dropna(subset=['input_lang','output_lang'])\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(df[\"input_lang\"], df[\"output_lang\"], test_size=0.20, random_state=42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dDYgLyrQxDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_en = [preprocess_sentence(text) for text in df_train[\"input_lang\"].values]\n",
        "df_es = [preprocess_sentence(text) for text in df_train[\"output_lang\"].values]\n",
        "\n",
        "# df_en = [preprocess_sentence(text) for text in X_train]\n",
        "# df_es = [preprocess_sentence(text) for text in y_train]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlmVpuF9QxPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqHAisSWbKr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(targ_lang, inp_lang):\n",
        "  # creating cleaned input, output pairs\n",
        "  # targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zuo5jufpbWMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "# num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(df_es,df_en)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5HYgGXrbWRE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb372a5f-3ba2-45c8-f57a-8c527d404994"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "228 228 58 58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCOpkGFGbWUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myKpH5XobWf6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "d9cb12e7-3662-4553-880d-1d874b0a51ce"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "2 ----> <start>\n",
            "15 ----> what\n",
            "22 ----> are\n",
            "5 ----> the\n",
            "345 ----> five\n",
            "346 ----> boroughs\n",
            "6 ----> of\n",
            "1 ----> entity\n",
            "4 ----> ?\n",
            "3 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "4 ----> ¿\n",
            "64 ----> cuales\n",
            "35 ----> son\n",
            "11 ----> los\n",
            "487 ----> cinco\n",
            "488 ----> condados\n",
            "6 ----> de\n",
            "489 ----> nueva\n",
            "490 ----> york\n",
            "3 ----> ?\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0cnTYPWbWd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkePjr8MdolW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "471c9599-866a-422a-a7a9-101f30a12e21"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 17]), TensorShape([64, 22]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhxQkg4Udour",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8SxPYMidosX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6735e526-9756-4d3b-aa1f-f8a87a330edc"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 17, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OD16j6DdoqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESFLQ7_sdooP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b7bbe91f-2c33-4f7f-c3b9-83c9d2842054"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 17, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtfRRtzjdojJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvARuVYPdohB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9512c64a-37ee-4178-deea-7fc44f296efd"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 519)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3aazuAgd5XG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20PXB-6Rd5-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iE_j31cd58K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv_OEbIJd55U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd1ebd63-9eaf-469c-a69a-f98c3fdcf2a8"
      },
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "  \n",
        "  if total_loss<0.005:\n",
        "    break\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.7709\n",
            "Epoch 1 Loss 2.6980\n",
            "Time taken for 1 epoch 45.40557098388672 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.4222\n",
            "Epoch 2 Loss 2.3376\n",
            "Time taken for 1 epoch 16.895276069641113 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 2.1680\n",
            "Epoch 3 Loss 2.2177\n",
            "Time taken for 1 epoch 16.598764419555664 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.9861\n",
            "Epoch 4 Loss 2.0608\n",
            "Time taken for 1 epoch 16.93299150466919 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 2.0625\n",
            "Epoch 5 Loss 1.9669\n",
            "Time taken for 1 epoch 16.551718711853027 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.8052\n",
            "Epoch 6 Loss 1.8737\n",
            "Time taken for 1 epoch 16.779998302459717 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 1.7569\n",
            "Epoch 7 Loss 1.7624\n",
            "Time taken for 1 epoch 16.68962812423706 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 1.8383\n",
            "Epoch 8 Loss 1.7702\n",
            "Time taken for 1 epoch 16.8481547832489 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 1.7052\n",
            "Epoch 9 Loss 1.6878\n",
            "Time taken for 1 epoch 16.47129511833191 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 1.6024\n",
            "Epoch 10 Loss 1.6707\n",
            "Time taken for 1 epoch 16.725659608840942 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 1.5986\n",
            "Epoch 11 Loss 1.6063\n",
            "Time taken for 1 epoch 16.549479484558105 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 1.4707\n",
            "Epoch 12 Loss 1.5793\n",
            "Time taken for 1 epoch 16.707579851150513 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 1.6748\n",
            "Epoch 13 Loss 1.5579\n",
            "Time taken for 1 epoch 16.429550409317017 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 1.3522\n",
            "Epoch 14 Loss 1.4607\n",
            "Time taken for 1 epoch 16.785094261169434 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 1.4676\n",
            "Epoch 15 Loss 1.4541\n",
            "Time taken for 1 epoch 16.37035584449768 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 1.4136\n",
            "Epoch 16 Loss 1.4099\n",
            "Time taken for 1 epoch 16.626585245132446 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 1.3948\n",
            "Epoch 17 Loss 1.3857\n",
            "Time taken for 1 epoch 16.437294244766235 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 1.4443\n",
            "Epoch 18 Loss 1.3688\n",
            "Time taken for 1 epoch 16.586405754089355 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 1.3181\n",
            "Epoch 19 Loss 1.3072\n",
            "Time taken for 1 epoch 16.39630150794983 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 1.1987\n",
            "Epoch 20 Loss 1.2799\n",
            "Time taken for 1 epoch 16.588627576828003 sec\n",
            "\n",
            "Epoch 21 Batch 0 Loss 1.2932\n",
            "Epoch 21 Loss 1.2400\n",
            "Time taken for 1 epoch 16.52457904815674 sec\n",
            "\n",
            "Epoch 22 Batch 0 Loss 1.3078\n",
            "Epoch 22 Loss 1.1845\n",
            "Time taken for 1 epoch 16.73224139213562 sec\n",
            "\n",
            "Epoch 23 Batch 0 Loss 1.3060\n",
            "Epoch 23 Loss 1.1984\n",
            "Time taken for 1 epoch 16.458012342453003 sec\n",
            "\n",
            "Epoch 24 Batch 0 Loss 1.1421\n",
            "Epoch 24 Loss 1.1162\n",
            "Time taken for 1 epoch 16.596981525421143 sec\n",
            "\n",
            "Epoch 25 Batch 0 Loss 1.0950\n",
            "Epoch 25 Loss 1.1038\n",
            "Time taken for 1 epoch 16.40342950820923 sec\n",
            "\n",
            "Epoch 26 Batch 0 Loss 1.1354\n",
            "Epoch 26 Loss 1.0685\n",
            "Time taken for 1 epoch 16.61032223701477 sec\n",
            "\n",
            "Epoch 27 Batch 0 Loss 1.1157\n",
            "Epoch 27 Loss 1.0479\n",
            "Time taken for 1 epoch 16.448975324630737 sec\n",
            "\n",
            "Epoch 28 Batch 0 Loss 1.0868\n",
            "Epoch 28 Loss 1.0077\n",
            "Time taken for 1 epoch 16.65331220626831 sec\n",
            "\n",
            "Epoch 29 Batch 0 Loss 1.1206\n",
            "Epoch 29 Loss 1.0156\n",
            "Time taken for 1 epoch 16.501919984817505 sec\n",
            "\n",
            "Epoch 30 Batch 0 Loss 0.9458\n",
            "Epoch 30 Loss 0.9655\n",
            "Time taken for 1 epoch 16.759321212768555 sec\n",
            "\n",
            "Epoch 31 Batch 0 Loss 0.8970\n",
            "Epoch 31 Loss 0.9415\n",
            "Time taken for 1 epoch 16.45288062095642 sec\n",
            "\n",
            "Epoch 32 Batch 0 Loss 0.8272\n",
            "Epoch 32 Loss 0.8784\n",
            "Time taken for 1 epoch 16.68396544456482 sec\n",
            "\n",
            "Epoch 33 Batch 0 Loss 0.8593\n",
            "Epoch 33 Loss 0.8667\n",
            "Time taken for 1 epoch 16.60853147506714 sec\n",
            "\n",
            "Epoch 34 Batch 0 Loss 0.8407\n",
            "Epoch 34 Loss 0.8480\n",
            "Time taken for 1 epoch 16.71715474128723 sec\n",
            "\n",
            "Epoch 35 Batch 0 Loss 0.8468\n",
            "Epoch 35 Loss 0.8195\n",
            "Time taken for 1 epoch 16.522141218185425 sec\n",
            "\n",
            "Epoch 36 Batch 0 Loss 0.7155\n",
            "Epoch 36 Loss 0.7812\n",
            "Time taken for 1 epoch 16.661625623703003 sec\n",
            "\n",
            "Epoch 37 Batch 0 Loss 0.7545\n",
            "Epoch 37 Loss 0.7784\n",
            "Time taken for 1 epoch 16.45691418647766 sec\n",
            "\n",
            "Epoch 38 Batch 0 Loss 0.7436\n",
            "Epoch 38 Loss 0.7282\n",
            "Time taken for 1 epoch 16.653586626052856 sec\n",
            "\n",
            "Epoch 39 Batch 0 Loss 0.6976\n",
            "Epoch 39 Loss 0.7158\n",
            "Time taken for 1 epoch 16.472109079360962 sec\n",
            "\n",
            "Epoch 40 Batch 0 Loss 0.6719\n",
            "Epoch 40 Loss 0.6986\n",
            "Time taken for 1 epoch 16.668829679489136 sec\n",
            "\n",
            "Epoch 41 Batch 0 Loss 0.6471\n",
            "Epoch 41 Loss 0.6582\n",
            "Time taken for 1 epoch 16.564072608947754 sec\n",
            "\n",
            "Epoch 42 Batch 0 Loss 0.6159\n",
            "Epoch 42 Loss 0.6321\n",
            "Time taken for 1 epoch 16.70638632774353 sec\n",
            "\n",
            "Epoch 43 Batch 0 Loss 0.6524\n",
            "Epoch 43 Loss 0.6224\n",
            "Time taken for 1 epoch 16.548694133758545 sec\n",
            "\n",
            "Epoch 44 Batch 0 Loss 0.6409\n",
            "Epoch 44 Loss 0.6119\n",
            "Time taken for 1 epoch 16.686887502670288 sec\n",
            "\n",
            "Epoch 45 Batch 0 Loss 0.5680\n",
            "Epoch 45 Loss 0.5761\n",
            "Time taken for 1 epoch 16.550772190093994 sec\n",
            "\n",
            "Epoch 46 Batch 0 Loss 0.5681\n",
            "Epoch 46 Loss 0.5697\n",
            "Time taken for 1 epoch 16.904128313064575 sec\n",
            "\n",
            "Epoch 47 Batch 0 Loss 0.5436\n",
            "Epoch 47 Loss 0.5421\n",
            "Time taken for 1 epoch 16.39633059501648 sec\n",
            "\n",
            "Epoch 48 Batch 0 Loss 0.5332\n",
            "Epoch 48 Loss 0.5181\n",
            "Time taken for 1 epoch 16.64652729034424 sec\n",
            "\n",
            "Epoch 49 Batch 0 Loss 0.5124\n",
            "Epoch 49 Loss 0.5060\n",
            "Time taken for 1 epoch 16.403693199157715 sec\n",
            "\n",
            "Epoch 50 Batch 0 Loss 0.4844\n",
            "Epoch 50 Loss 0.4979\n",
            "Time taken for 1 epoch 16.6666316986084 sec\n",
            "\n",
            "Epoch 51 Batch 0 Loss 0.4398\n",
            "Epoch 51 Loss 0.4658\n",
            "Time taken for 1 epoch 16.60168433189392 sec\n",
            "\n",
            "Epoch 52 Batch 0 Loss 0.4258\n",
            "Epoch 52 Loss 0.4620\n",
            "Time taken for 1 epoch 16.63260555267334 sec\n",
            "\n",
            "Epoch 53 Batch 0 Loss 0.4181\n",
            "Epoch 53 Loss 0.4446\n",
            "Time taken for 1 epoch 16.571043252944946 sec\n",
            "\n",
            "Epoch 54 Batch 0 Loss 0.4439\n",
            "Epoch 54 Loss 0.4334\n",
            "Time taken for 1 epoch 16.620375871658325 sec\n",
            "\n",
            "Epoch 55 Batch 0 Loss 0.4324\n",
            "Epoch 55 Loss 0.4196\n",
            "Time taken for 1 epoch 16.43258786201477 sec\n",
            "\n",
            "Epoch 56 Batch 0 Loss 0.4028\n",
            "Epoch 56 Loss 0.4035\n",
            "Time taken for 1 epoch 16.560630321502686 sec\n",
            "\n",
            "Epoch 57 Batch 0 Loss 0.3700\n",
            "Epoch 57 Loss 0.3945\n",
            "Time taken for 1 epoch 16.439271211624146 sec\n",
            "\n",
            "Epoch 58 Batch 0 Loss 0.3382\n",
            "Epoch 58 Loss 0.3669\n",
            "Time taken for 1 epoch 16.62632656097412 sec\n",
            "\n",
            "Epoch 59 Batch 0 Loss 0.3819\n",
            "Epoch 59 Loss 0.3741\n",
            "Time taken for 1 epoch 16.430624961853027 sec\n",
            "\n",
            "Epoch 60 Batch 0 Loss 0.3177\n",
            "Epoch 60 Loss 0.3479\n",
            "Time taken for 1 epoch 16.69275665283203 sec\n",
            "\n",
            "Epoch 61 Batch 0 Loss 0.3109\n",
            "Epoch 61 Loss 0.3468\n",
            "Time taken for 1 epoch 16.58895468711853 sec\n",
            "\n",
            "Epoch 62 Batch 0 Loss 0.3545\n",
            "Epoch 62 Loss 0.3450\n",
            "Time taken for 1 epoch 16.690741062164307 sec\n",
            "\n",
            "Epoch 63 Batch 0 Loss 0.3324\n",
            "Epoch 63 Loss 0.3272\n",
            "Time taken for 1 epoch 16.740347146987915 sec\n",
            "\n",
            "Epoch 64 Batch 0 Loss 0.3153\n",
            "Epoch 64 Loss 0.3190\n",
            "Time taken for 1 epoch 16.853238821029663 sec\n",
            "\n",
            "Epoch 65 Batch 0 Loss 0.3311\n",
            "Epoch 65 Loss 0.3277\n",
            "Time taken for 1 epoch 17.001484632492065 sec\n",
            "\n",
            "Epoch 66 Batch 0 Loss 0.3023\n",
            "Epoch 66 Loss 0.3024\n",
            "Time taken for 1 epoch 17.08065700531006 sec\n",
            "\n",
            "Epoch 67 Batch 0 Loss 0.3165\n",
            "Epoch 67 Loss 0.2945\n",
            "Time taken for 1 epoch 16.906721591949463 sec\n",
            "\n",
            "Epoch 68 Batch 0 Loss 0.2666\n",
            "Epoch 68 Loss 0.2804\n",
            "Time taken for 1 epoch 17.174692153930664 sec\n",
            "\n",
            "Epoch 69 Batch 0 Loss 0.3055\n",
            "Epoch 69 Loss 0.2920\n",
            "Time taken for 1 epoch 17.149115324020386 sec\n",
            "\n",
            "Epoch 70 Batch 0 Loss 0.2626\n",
            "Epoch 70 Loss 0.2758\n",
            "Time taken for 1 epoch 17.13289475440979 sec\n",
            "\n",
            "Epoch 71 Batch 0 Loss 0.2577\n",
            "Epoch 71 Loss 0.2721\n",
            "Time taken for 1 epoch 16.99531602859497 sec\n",
            "\n",
            "Epoch 72 Batch 0 Loss 0.2699\n",
            "Epoch 72 Loss 0.2561\n",
            "Time taken for 1 epoch 17.125110864639282 sec\n",
            "\n",
            "Epoch 73 Batch 0 Loss 0.2262\n",
            "Epoch 73 Loss 0.2361\n",
            "Time taken for 1 epoch 16.917855739593506 sec\n",
            "\n",
            "Epoch 74 Batch 0 Loss 0.2314\n",
            "Epoch 74 Loss 0.2360\n",
            "Time taken for 1 epoch 17.062206983566284 sec\n",
            "\n",
            "Epoch 75 Batch 0 Loss 0.2428\n",
            "Epoch 75 Loss 0.2363\n",
            "Time taken for 1 epoch 16.89109206199646 sec\n",
            "\n",
            "Epoch 76 Batch 0 Loss 0.2103\n",
            "Epoch 76 Loss 0.2252\n",
            "Time taken for 1 epoch 17.05125617980957 sec\n",
            "\n",
            "Epoch 77 Batch 0 Loss 0.2478\n",
            "Epoch 77 Loss 0.2296\n",
            "Time taken for 1 epoch 16.87294888496399 sec\n",
            "\n",
            "Epoch 78 Batch 0 Loss 0.1974\n",
            "Epoch 78 Loss 0.2104\n",
            "Time taken for 1 epoch 16.940483331680298 sec\n",
            "\n",
            "Epoch 79 Batch 0 Loss 0.2035\n",
            "Epoch 79 Loss 0.2161\n",
            "Time taken for 1 epoch 16.806300163269043 sec\n",
            "\n",
            "Epoch 80 Batch 0 Loss 0.1955\n",
            "Epoch 80 Loss 0.2022\n",
            "Time taken for 1 epoch 17.064337730407715 sec\n",
            "\n",
            "Epoch 81 Batch 0 Loss 0.2142\n",
            "Epoch 81 Loss 0.2007\n",
            "Time taken for 1 epoch 16.55070948600769 sec\n",
            "\n",
            "Epoch 82 Batch 0 Loss 0.1849\n",
            "Epoch 82 Loss 0.2064\n",
            "Time taken for 1 epoch 16.78358268737793 sec\n",
            "\n",
            "Epoch 83 Batch 0 Loss 0.1787\n",
            "Epoch 83 Loss 0.2013\n",
            "Time taken for 1 epoch 16.633238077163696 sec\n",
            "\n",
            "Epoch 84 Batch 0 Loss 0.2099\n",
            "Epoch 84 Loss 0.1858\n",
            "Time taken for 1 epoch 16.756825923919678 sec\n",
            "\n",
            "Epoch 85 Batch 0 Loss 0.1658\n",
            "Epoch 85 Loss 0.1767\n",
            "Time taken for 1 epoch 16.69647741317749 sec\n",
            "\n",
            "Epoch 86 Batch 0 Loss 0.1796\n",
            "Epoch 86 Loss 0.1725\n",
            "Time taken for 1 epoch 16.811269998550415 sec\n",
            "\n",
            "Epoch 87 Batch 0 Loss 0.1690\n",
            "Epoch 87 Loss 0.1631\n",
            "Time taken for 1 epoch 16.621734857559204 sec\n",
            "\n",
            "Epoch 88 Batch 0 Loss 0.1714\n",
            "Epoch 88 Loss 0.1660\n",
            "Time taken for 1 epoch 16.823660850524902 sec\n",
            "\n",
            "Epoch 89 Batch 0 Loss 0.1571\n",
            "Epoch 89 Loss 0.1611\n",
            "Time taken for 1 epoch 16.632452964782715 sec\n",
            "\n",
            "Epoch 90 Batch 0 Loss 0.1437\n",
            "Epoch 90 Loss 0.1520\n",
            "Time taken for 1 epoch 16.76458764076233 sec\n",
            "\n",
            "Epoch 91 Batch 0 Loss 0.1507\n",
            "Epoch 91 Loss 0.1482\n",
            "Time taken for 1 epoch 16.670243978500366 sec\n",
            "\n",
            "Epoch 92 Batch 0 Loss 0.1334\n",
            "Epoch 92 Loss 0.1466\n",
            "Time taken for 1 epoch 16.812808513641357 sec\n",
            "\n",
            "Epoch 93 Batch 0 Loss 0.1482\n",
            "Epoch 93 Loss 0.1430\n",
            "Time taken for 1 epoch 16.580586433410645 sec\n",
            "\n",
            "Epoch 94 Batch 0 Loss 0.1289\n",
            "Epoch 94 Loss 0.1338\n",
            "Time taken for 1 epoch 16.777726411819458 sec\n",
            "\n",
            "Epoch 95 Batch 0 Loss 0.1466\n",
            "Epoch 95 Loss 0.1268\n",
            "Time taken for 1 epoch 16.522988319396973 sec\n",
            "\n",
            "Epoch 96 Batch 0 Loss 0.1293\n",
            "Epoch 96 Loss 0.1294\n",
            "Time taken for 1 epoch 16.722838878631592 sec\n",
            "\n",
            "Epoch 97 Batch 0 Loss 0.1399\n",
            "Epoch 97 Loss 0.1269\n",
            "Time taken for 1 epoch 16.6480073928833 sec\n",
            "\n",
            "Epoch 98 Batch 0 Loss 0.1212\n",
            "Epoch 98 Loss 0.1157\n",
            "Time taken for 1 epoch 16.77735161781311 sec\n",
            "\n",
            "Epoch 99 Batch 0 Loss 0.1048\n",
            "Epoch 99 Loss 0.1040\n",
            "Time taken for 1 epoch 16.685495853424072 sec\n",
            "\n",
            "Epoch 100 Batch 0 Loss 0.1023\n",
            "Epoch 100 Loss 0.1052\n",
            "Time taken for 1 epoch 16.955665588378906 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKxxkhwwd5Tp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  # attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "\n",
        "\n",
        "\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    # attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    # attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      # return result, sentence, attention_plot\n",
        "      return result, sentence\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  # return result, sentence, attention_plot\n",
        "  return result, sentence"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WiMynXod5RC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11reOrQ_d5Oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  # result, sentence, attention_plot = evaluate(sentence)\n",
        "  result, sentence = evaluate(sentence)\n",
        "\n",
        "\n",
        "  # print('Input: %s' % (sentence))\n",
        "  # print('Predicted translation: {}'.format(result))\n",
        "  # print(result)\n",
        "  return result\n",
        "  # attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  # plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63S3iNZ6d5Lw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3881dfbb-1ed4-4943-c6d8-fd247927d149"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7eff6be78438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cfz5VHI9bWPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # df_test = pd.read_csv('/content/drive/My Drive/data/test/en-ro-test.csv')\n",
        "df_test = pd.read_csv('/content/drive/My Drive/data/template/en-es-test-template.csv')\n",
        "df_test=df_test.dropna(subset=['input_lang','output_lang'])\n",
        "# # df_test = df_test[df_test.correctly_annotated==1]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJsM8NIBV3Mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_test.shape"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6yAxtp0URvp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4c9e33eb-382e-4c88-94f3-18901f5e74f6"
      },
      "source": [
        "count=0\n",
        "w=0\n",
        "e=0\n",
        "for index, row in df_test.iterrows():\n",
        "  try:\n",
        "    trans = translate(row[\"input_lang\"])\n",
        "    sentence = preprocess_sentence(row[\"output_lang\"])\n",
        "    if trans[:-1]== sentence[8:]:\n",
        "      count+=1\n",
        "      # print(row[\"english\"])\n",
        "    else:\n",
        "      w+=1\n",
        "      print(\"expected: \"+row[\"output_lang\"]+\"  \"+\"translation: \"+trans) \n",
        "  except KeyError:\n",
        "    e+=1\n",
        "    print(\"error_sentence: \" + row[\"input_lang\"])\n",
        "    continue\n",
        "\n",
        "# df_en = [preprocess_sentence(text) for text in X_test]\n",
        "# df_es = [preprocess_sentence(text) for text in y_test]\n",
        "\n",
        "# for i in range(len(df_en)):\n",
        "#   try:\n",
        "#     trans = translate(df_en[i])\n",
        "#     sentence = preprocess_sentence(df_es[i])\n",
        "#     if trans[:-1]== sentence[8:]:\n",
        "#       count+=1\n",
        "#       # print(row[\"english\"])\n",
        "#     else:\n",
        "#       w+=1\n",
        "#       print(\"expected: \"+df_es[i]+\"  \"+\"translation: \"+trans) \n",
        "#   except KeyError:\n",
        "#     e+=1\n",
        "#     print(\"error_sentence: \" + df_en[i])\n",
        "#     continue"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "expected: dame todos los actores de películas dirigidas por entidad en las qué también haya actúado el mismo.  translation: dame todas las que tambien haya actuado en las que tambien haya actuado en las que tambien haya actuado en las que \n",
            "expected: ¿qué altura tiene entidad?  translation: ¿ como de alta es entidad ? <end> \n",
            "expected: ¿cuál es el apodo de san francisco?  translation: ¿ cual es el hijo mas largo ? <end> \n",
            "expected: dame todos los astronautas de entidad?  translation: dame todas las taikonautas . <end> \n",
            "expected: ¿dónde vive el primer ministor de entidad?  translation: ¿ cuantas personas que estudio gobierna en el primer ministor de entidad ? <end> \n",
            "expected: dame las ciudades hermanadas con entidad.  translation: dame todos los nietos de entidad . <end> \n",
            "expected: ¿qué otras armas desarrolló el inventor del entidad?  translation: ¿ en que peliculas actuan entidad y entidad ? <end> \n",
            "expected: ¿en qué año fue fundada la entidad que produce entidad?  translation: ¿ en que ano fue fundada la entidad en entidad ? <end> \n",
            "expected: ¿fue entidad química?  translation: ¿ quien produce el real madrid ? <end> \n",
            "expected: ¿cuál es la capital de entidad?  translation: ¿ cual es el hijo mas largo ? <end> \n",
            "expected: dame una lista de todos los trompeteros que fueron líderes de un grupo.  translation: dame todos los actores de entidad . <end> \n",
            "expected: dame todos los coches producidos en entidad.  translation: dame todos los jugadores de entidad . <end> \n",
            "expected: ¿cuántos hijos tuvo entidad?  translation: ¿ cuantos empleados tiene entidad ? <end> \n",
            "expected: ¿es michele obama la esposa de entidad?  translation: ¿ quien es el entrenador del equipo de entidad ? <end> \n",
            "error_sentence: was entity a jew?\n",
            "expected: dame todos los libros de wiliam goldman con más de 300 páginas.  translation: dame todas las paginas . <end> \n",
            "expected: ¿qué surfistas profesionales nacieron en las entidad?  translation: ¿ que surfistas profesionales nacieron en entidad ? <end> \n",
            "expected: ¿en qué películas con entidad están dirigidas por él mismo?  translation: ¿ en que pais nace el entidad ? <end> \n",
            "expected: ¿cuál es el río más largo?  translation: ¿ cual es el hijo mas largo ? <end> \n",
            "expected: ¿cuántos habitantes tiene maribor?  translation: ¿ cuantas tiendas entidad hay ? <end> \n",
            "expected: dame una lista de todos los lagos en entidad.  translation: dame una lista de todos los lideres de web de entidad . <end> \n",
            "expected: ¿quién es el gobernador de entidad?  translation: ¿ quien es el presidente de entidad ? <end> \n",
            "expected: ¿cúando se fundaron los entidad?  translation: ¿ cuando murio el creador de entidad ? <end> \n",
            "expected: ¿quién fundó intel?  translation: ¿ quien produce entidad ? <end> \n",
            "expected: ¿por qué ciudades pasa el río entidad?  translation: ¿ por que imperio york ? <end> \n",
            "expected: dame todas las películas que haya dirigido entidad.  translation: dame todas las empresas de munich ? <end> \n",
            "expected: ¿qué partido gobierna en entidad?  translation: ¿ donde vive el verdadero nombre de entidad ? <end> \n",
            "expected: ¿cúal es el entidad del entidad?  translation: ¿ cual es el nombre de entidad ? <end> \n",
            "expected: ¿cuántos idiomas oficiales se hablan en las entidad?  translation: ¿ cuantos idiomas se hablan en cuantas misiones espaciales ha habido ? <end> \n",
            "expected: ¿enseñame todas las canciones de entidad que aparecieron entre 1980 y 1990.  translation: ¿ que actores nacieron en entidad ? <end> \n",
            "expected: dame todos las skateboarders profesionales de entidad.  translation: dame todos los nombres propios femeninos . <end> \n",
            "expected: cómo de hondo es el lago placid?  translation: ¿ donde murio entidad ? <end> \n",
            "expected: ¿dónde nació bach?  translation: ¿ donde empieza entidad ? <end> \n",
            "expected: ¿desemboca el isar en un lago?  translation: ¿ cual es el hijo mas mayor de entidad ? <end> \n",
            "expected: dame todos los actores llamados baldwin.  translation: dame todas las empresas de munich ? <end> \n",
            "expected: ¿quién es el jugador más alto de los entidad?  translation: ¿ quien es el jugador de los entidad de la cuidad de entidad ? <end> \n",
            "expected: ¿cuántas películas de james bond existen?  translation: ¿ cuantas peliculas ha actuado entidad ? <end> \n",
            "expected: ¿cuándo es entidad?  translation: ¿ cuando murio entidad ? <end> \n",
            "expected: dame todos los actores nacidos en berlin.  translation: dame todas las que peliculas con mas de entidad . <end> \n",
            "expected: ¿qué abrevia cpu?  translation: ¿ cuantas peliculas dirigio park chan wook ? <end> \n",
            "expected: ¿cuál ha sido la posición de ranking más baja de entidad en el ranking mundial de la entidad?  translation: ¿ cual es el ranking mundial de ranking mundial de la posicion de ranking mundial de la posicion de ranking mundial de \n",
            "expected: dame las capitales de todos los países que atraviesa el entidad.  translation: dame todos los actores de peliculas dirigidas por entidad . <end> \n",
            "expected: ¿cuál es la película de entidad con el mayor presupuesto?  translation: ¿ cual es el nacimiento nombre de entidad ? <end> \n",
            "expected: ¿qué actor ha actuado en el mayor número de películas?  translation: ¿ que actor ha actuado en cuantas peliculas ha actuado el fundador de james fundadas por entidad en cuantas peliculas ha actuado \n",
            "expected: ¿está james bond casado?  translation: ¿ todavia vive entidad ? <end> \n",
            "expected: dame todos los actores nacidos en paris después de 1950.  translation: dame todas las cuidades en new jersey que tengan mas de habitantes . <end> \n",
            "expected: dame todos los astronautas de la esa.  translation: dame todas las taikonautas . <end> \n",
            "expected: dame todos los días festivos en entidad.  translation: dame todas las taikonautas . <end> \n",
            "expected: ¿que jugadores de futbol han nacido en entidad?  translation: ¿ en que pais nace el entidad ? <end> \n",
            "expected: ¿fue entidad a la universidad?  translation: ¿ todavia vive entidad ? <end> \n",
            "expected: ¿cuántos hijos tiene entidad?  translation: ¿ cuantos empleados tiene entidad ? <end> \n",
            "expected: ¿qué artistas nacieron en la misma fecha que entidad?  translation: ¿ que artistas nacieron en que productos de software han sido fundadas por el fundador de entidad ? <end> \n",
            "expected: ¿quien protagoniza peliculas españolas producidas por entidad?  translation: ¿ quien es el jugador de entidad ? <end> \n",
            "expected: ¿quien es el manager de real madrid?  translation: ¿ quien es el presidente de entidad ? <end> \n",
            "expected: ¿que peliculas protagonizadas por entidad han sido dirigidas por entidad?  translation: ¿ en que ano que ano que ano que ano que ano que ano que ano que ano que ano que ano \n",
            "expected: ¿qué subsidiario de entidad vuela en entidad y en berlin?  translation: ¿ en que aerolineas forman parte del la misma fecha que peliculas actuan entidad y en que imperio antiguo pagaria con granos \n",
            "expected: dame todas las naves espaciales que han volado a marte  translation: ¿ que paises tienen mas de entidad que pertenezcan a entidad . <end> \n",
            "expected: muestrame todas las personas nacidas en entidad  translation: ¿ por que imperio antiguo pagaria con granos de tui travel vuela en entidad ? <end> \n",
            "error_sentence: which entity in entity has the most visitors?\n",
            "expected: ¿cuál es la entidad mas alta en entidad?  translation: ¿ cual es el punto mas alto en entidad ? <end> \n",
            "expected: ¿dónde estudio el arquitecto de la entidad?  translation: ¿ en que pais nace el mayor numero de la alianza entidad ? <end> \n",
            "expected: ¿cuál es la diferencia de altura entra el entidad y entidad?  translation: ¿ cual es el vino melon de programacion fueron influenciados por garry mashall actuo entidad ? <end> \n",
            "expected: ¿quién es el entidad de rotterdam?  translation: ¿ quien es el entidad ? <end> \n",
            "expected: ¿que volcanos han erupcionado en japon desde el 2000?  translation: ¿ que actor hizo el rio mas largo ? <end> \n",
            "expected: quien es el jugador de entidad mas alto?  translation: ¿ quien es el jugador de entidad de la cuidad de entidad ? <end> \n",
            "error_sentence: who was on the entity mission?\n",
            "expected: ¿qué compañías de electrónica fueron fundadas en entidad?  translation: ¿ que aerolineas forman parte del la alianza entidad ? <end> \n",
            "error_sentence: what is the atmosphere of the entity composed of?\n",
            "expected: ¿quiénes son los desarrolladores de entidad?  translation: ¿ quien son los desarrolladores de entidad ? <end> \n",
            "expected: ¿cuál es el nombre de la escuela donde la esposa de obama estudió?  translation: ¿ cuales fueron los cuatro nombre de entidad ? <end> \n",
            "expected: ¿cuál es la capital de entidad?  translation: ¿ cual es el hijo mas largo ? <end> \n",
            "error_sentence: when did the entity take place?\n",
            "expected: ¿quién escribió entidad?  translation: ¿ quien asesino a entidad ? <end> \n",
            "error_sentence: who is the most powerful entity?\n",
            "error_sentence: how many goals did entity score?\n",
            "error_sentence: which entity won an entity?\n",
            "expected: ¿quién creó family guy?  translation: ¿ quien creo entidad ? <end> \n",
            "error_sentence: how many grand-children did entity have?\n",
            "expected: ¿cuál es el río más largo de china?  translation: ¿ cuales son los cinco condados de web oficial de entidad ? <end> \n",
            "error_sentence: how many calories does a entity have?\n",
            "error_sentence: how many emperors did entity have?\n",
            "expected: ¿en qué películas participa entidad?  translation: ¿ cual es la zona horaria en entidad ? <end> \n",
            "expected: muéstrame todos los museos en entidad  translation: muestrame todas las organizaciones entidads sin animo de lucro <end> \n",
            "expected: ¿quién es el entrenador del equipo de entidad de entidad?  translation: ¿ quien es el entrenador del equipo de entidad ? <end> \n",
            "expected: ¿qué tipo de música tocaba entidad?  translation: muestrame todas las taikonautas . <end> \n",
            "error_sentence: what are the entity signs?\n",
            "error_sentence: who became president after entity died?\n",
            "expected: ¿quién mató a césar?  translation: ¿ quien asesino a entidad ? <end> \n",
            "expected: dame actores ingleses protagonizando lovesick.  translation: muestrame el libro escrito por entidad . <end> \n",
            "error_sentence: what is the nick name of entity?\n",
            "error_sentence: what is the revenue of entity?\n",
            "expected: cual libros fueron escrito por danielle ¿acero?  translation: ¿ que cuevas tienen mas de entradas ? <end> \n",
            "error_sentence: are there any castles in the entity?\n",
            "expected: ¿cúando se fundó jack wolfskin?  translation: ¿ cuando fue fundada la provincia de entidad ? <end> \n",
            "expected: quien es el gobernador de ¿entidad?  translation: ¿ quien es el presidente de entidad ? <end> \n",
            "error_sentence: what was the name of the famous entity in 1836 in entity?\n",
            "error_sentence: when was the entity company founded?\n",
            "error_sentence: how many rivers and lakes are in entity?\n",
            "expected: dame las capitales de todos los países africanos.  translation: dame todas las plataformas de mean hamster software . <end> \n",
            "expected: ¿qué puentes son del mismo tipo que el entidad?  translation: ¿ que cientificos son conocidos por el entidad y el entidad ? <end> \n",
            "expected: ¿cuál es el estado más grande de los entidad?  translation: ¿ cual es el hijo mas grande del mundo ? <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxo5Pk25WfeE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43bdb3db-a6d8-42a5-aeb7-c71ab05c5211"
      },
      "source": [
        "count/df_test.shape[0]\n",
        "# count/len(X_test)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38414634146341464"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ6lYlb2Wfch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b37d9ff-14ed-4734-dc8d-f28c79063202"
      },
      "source": [
        "count"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWTvisE1rptx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "01deed8b-e858-446c-d7ec-888bdb959a6c"
      },
      "source": [
        "e/df_test.shape[0]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11585365853658537"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76opPRPirsbL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d02188f9-0321-4c1c-a078-6a735ee809b3"
      },
      "source": [
        "w/df_test.shape[0]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXwM8Z8Krsix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXkqrULWrsl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbcqzsbNrsgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PdmH4HsrseM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    }
  ]
}